{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "        AvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 11,176,512\n",
      "Trainable params: 0\n",
      "Non-trainable params: 11,176,512\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 105.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet = models.resnet18(pretrained=True).to(device)\n",
    "modules = list(resnet.children())[:-1] # delete the last fc layer.\n",
    "resnet = nn.Sequential(*modules)\n",
    "### Now set requires_grad to false\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "summary(resnet, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n",
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "i2t = transforms.ToTensor()\n",
    "img_path = '/home/zal/Data/VIRAT/Frames/pool/VIRAT_S_010100_00_000000_000060.jpg'\n",
    "img = Image.open(img_path).resize((224,224), Image.ANTIALIAS)\n",
    "print(img.size)\n",
    "img_tensor = i2t(img).view(1,3,224,224).to(device)\n",
    "print(img_tensor.size())\n",
    "output = resnet(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "512\n",
      "[0.9216135  0.97686046 0.9905396  1.1020446  0.9162096  0.8611425\n",
      " 0.98378366 1.1834332  0.930188   0.8503293  0.91363186 0.8783091\n",
      " 0.94831854 0.9198754  0.9552576  0.9923859  0.93271583 1.411642\n",
      " 0.96364564 0.79349697 0.8649549  1.088116   0.95795345 1.026588\n",
      " 0.97684944 0.93655413 1.0174981  1.0136442  0.9127933  0.94322765\n",
      " 0.84389174 0.8990822  1.0006639  0.8367958  0.9274169  0.81444883\n",
      " 0.92517376 1.0174005  0.94232756 0.94205654 0.9478178  0.88493603\n",
      " 0.8574134  1.0167197  0.90647984 0.8577888  0.8884006  1.1778312\n",
      " 0.91088176 0.8940386  0.9972493  0.9469083  0.8979219  0.9181129\n",
      " 0.9444447  1.0186722  1.1032861  0.9223024  1.0435795  0.962057\n",
      " 0.96511334 0.9931771  1.0151083  0.97268426 0.8997076  1.02887\n",
      " 0.7967973  0.9349797  1.0267674  0.83793485 0.9081586  0.84224427\n",
      " 0.92022204 0.93679637 0.94872415 0.94476956 0.9280246  0.9604612\n",
      " 0.89480823 0.8881407  0.9272965  1.0742751  1.0861243  1.2616334\n",
      " 0.86841655 0.9143988  0.8858454  0.8664511  1.0289305  0.8537963\n",
      " 0.7595228  0.8765432  0.90627164 0.97063047 0.87194103 0.8831367\n",
      " 0.9389295  0.8921113  0.9319409  0.89028263 1.0542607  0.98245114\n",
      " 0.97006935 1.0711607  1.0108747  0.81683064 0.97089064 0.96623427\n",
      " 0.8149772  0.99478245 0.9432605  0.8926391  0.8784553  0.8900882\n",
      " 0.849303   0.97078884 0.9267337  0.92568165 0.9424975  0.9729994\n",
      " 1.063921   0.9304881  0.9406275  0.87068707 0.9525552  0.76122004\n",
      " 0.8859542  0.927916   0.9861829  0.99082345 0.91148394 0.8735807\n",
      " 0.8399587  0.91584325 1.0364845  1.0658246  0.91620755 0.95373386\n",
      " 0.95484614 0.9365232  0.8916128  0.8354492  0.9575106  0.9673309\n",
      " 0.9224765  0.83106226 0.84029126 1.0521382  0.94448596 1.0686312\n",
      " 0.9141012  0.89324725 0.8786615  0.90762347 0.8443713  0.8938077\n",
      " 0.96996367 0.9320877  0.8372689  0.8811827  0.99406874 1.2294443\n",
      " 0.9911805  1.2922883  0.9818708  0.9336619  1.0121443  0.9162891\n",
      " 0.9309862  0.9990057  0.9110506  0.95152634 0.9028706  0.83743125\n",
      " 0.93809456 0.8161119  0.96323353 0.9231016  1.003507   0.85703665\n",
      " 0.90046644 0.94958955 1.3152431  0.94862026 0.95259905 0.93516016\n",
      " 0.9835955  0.97020817 0.8490771  0.94840413 0.9509112  0.8799898\n",
      " 1.0117054  1.1210707  0.84649247 0.9059044  0.97523224 0.9142651\n",
      " 0.9962936  0.9087155  0.85805964 0.9575689  1.1997695  0.8464437\n",
      " 1.0502352  0.8885164  0.87849575 0.87769955 0.98735994 1.0294083\n",
      " 0.76591665 0.87547785 0.9448342  0.9018037  0.99037194 0.93069357\n",
      " 0.9176736  0.8386528  0.85323817 0.9541549  0.9546342  0.9744242\n",
      " 0.8723243  0.87331206 0.903495   0.8360684  0.9816533  0.8947785\n",
      " 1.0108694  0.87449664 0.8735829  0.9365598  0.88384444 1.022072\n",
      " 0.8901667  0.9561473  0.9417456  1.0889254  0.8945869  0.97897196\n",
      " 0.91784585 0.8610656  1.0018678  0.8491095  0.86464643 0.9781052\n",
      " 0.99435914 0.85550845 0.8914285  1.0665687  1.0199071  0.96111065\n",
      " 0.9395884  0.8840802  0.9050918  1.264132   0.94295937 1.0883406\n",
      " 1.0219179  1.0789877  0.9957996  0.9732511  0.95163274 0.98960876\n",
      " 0.87066275 0.98934436 0.8915269  0.940253   0.9002782  0.916997\n",
      " 0.89332014 0.9224535  0.9114077  0.9189164  0.9480542  0.9761674\n",
      " 0.8970627  0.9142568  0.9669334  0.7664566  1.2751507  0.9285835\n",
      " 0.9290274  0.94776845 0.94572467 0.88383454 0.93966913 0.9350484\n",
      " 1.012944   0.86509985 0.9078992  0.9563597  0.8452473  0.8727491\n",
      " 0.9433212  0.8699498  0.90756124 1.1328003  0.89230496 0.9296387\n",
      " 0.8543966  0.9817642  0.89648765 0.8559893  1.0837076  0.9569694\n",
      " 0.8712454  1.0166873  1.016413   0.9674657  1.0661966  0.9205991\n",
      " 1.1914003  0.9437307  0.8245816  0.8633039  0.9888336  0.9441849\n",
      " 1.0702285  0.91128314 0.8724845  0.9838506  0.9426584  0.97369075\n",
      " 0.92801064 0.92762774 0.97213185 0.9282089  0.939239   0.8648572\n",
      " 0.9954659  0.95428115 0.8509439  0.89694166 0.9272263  0.886105\n",
      " 0.95401335 0.8701671  0.9629165  0.90106475 0.90412986 0.9439063\n",
      " 0.9218557  1.1840806  0.9680755  0.821185   0.91227263 0.89514154\n",
      " 0.85243845 1.0230402  0.854036   0.9503055  0.9451124  0.9096735\n",
      " 0.9242917  0.85057366 0.9173146  1.0233498  0.9672225  0.8789388\n",
      " 0.92269737 0.9718618  0.8933968  0.88105744 1.0787839  0.8589269\n",
      " 1.013648   1.020351   0.931683   0.9523735  1.0218143  0.9562676\n",
      " 0.92493206 0.84874344 0.8772801  0.9657395  0.89070386 0.84270394\n",
      " 0.921569   0.9457721  1.0677202  0.9465125  1.0274444  0.9938385\n",
      " 1.029392   0.9836289  0.90967155 1.0332396  0.8997608  0.94663286\n",
      " 0.99076104 0.9815785  0.8588358  0.99028957 0.9995864  0.93450373\n",
      " 0.7721268  0.991408   0.95370543 0.93507546 1.165484   1.0255193\n",
      " 0.86607176 0.8982961  0.96223783 0.9057945  0.9718646  0.86625665\n",
      " 0.91422576 0.88811165 0.89284134 0.8703491  0.8807188  0.9164838\n",
      " 1.0072125  1.0341207  0.9213419  0.9366882  0.8261681  0.88269466\n",
      " 0.8855084  0.9023966  0.9456095  0.9041412  0.98434085 0.8779472\n",
      " 0.97316456 1.0614928  0.87446284 0.98011357 0.90996426 0.9525474\n",
      " 0.8594363  0.9422556  0.9727626  1.1540507  0.8860446  0.9754729\n",
      " 0.88543904 0.8746025  0.8704201  0.8696119  0.8534965  1.0213989\n",
      " 1.0383378  0.90457207 0.97458297 0.90716505 1.0058546  0.9476095\n",
      " 0.93862665 0.8982055  1.003706   0.9535751  0.8550155  0.9246884\n",
      " 0.87372154 0.9862633  0.9998373  0.96051323 1.0731385  0.90439427\n",
      " 0.9304613  0.88455564 0.8915215  0.90627205 0.9761141  0.94329715\n",
      " 0.97981775 0.9344309  0.91868234 1.0179976  0.789532   0.9230388\n",
      " 0.9776683  0.93022287 0.8984241  0.9301761  0.9089775  0.8699168\n",
      " 0.9874234  1.0384643  0.8621636  0.8983233  1.0959257  0.90323055\n",
      " 1.014958   0.97888106 1.0898138  0.82884955 0.9904726  1.0221319\n",
      " 0.9925547  0.8674578  0.88879347 0.9200514  0.83056265 0.91424173\n",
      " 0.9874474  0.97590184 0.96267706 0.93954474 0.9542015  0.9075541\n",
      " 0.8711378  0.84558135 1.1143138  0.98871136 0.89779425 0.9499978\n",
      " 1.0516316  0.9985886 ]\n"
     ]
    }
   ],
   "source": [
    "output = output.to('cpu').view(-1)\n",
    "npo = output.data.numpy()\n",
    "print(type(npo))\n",
    "print(npo.size)\n",
    "print(npo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
